 {
   "cell_type": "code",
   "execution_count": null,
   "id": "32276227-d9fd-42c9-9a88-afba92d21e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn matplotlib numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f5e5b-f702-4aab-ae45-7383a6465a25",
   "metadata": {},
   "source": [
    "# 1. KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d65542-4329-4602-b165-f3b6f03c1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(\"Iris datasets loaded: \\n\")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.1)\n",
    "print('Dataset split into train and test\\n')\n",
    "print('Size of training data: ',X_train.shape, Y_train.shape)\n",
    "\n",
    "for i in range(len(iris.target_names)):\n",
    "    print(f'Label {i}: {iris.target_names[i]} ')\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 1)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "print('\\nResult of classification using KNN with K=1 ')\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    print(f'Sample: {X_test[i]} - Actual: {Y_test[i]} - Predict: {Y_pred[i]}')\n",
    "\n",
    "print('\\nClassifiacation accuracy: ',classifier.score(X_test, Y_test))\n",
    "print('\\nConfussion Matrics: \\n', confusion_matrix(Y_test, Y_pred))\n",
    "print('\\nClassifiaction Report: \\n',classification_report(Y_test, Y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ecebf-c71a-4e0a-82ad-b8255018d46d",
   "metadata": {},
   "source": [
    "# 2. PCA(Principle Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bf170-f201-4519-aba3-1b4cd2cc016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets, decomposition\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d', elev=48, azim=134)\n",
    "ax.set_position([0, 0, 0.95, 1])\n",
    "ax.cla()\n",
    "\n",
    "pca = decomposition.PCA(n_components = 3)\n",
    "pca.fit(X)\n",
    "\n",
    "X = pca.transform(X)\n",
    "\n",
    "for name, label in [('setosa', 0), ('versicolor', 1), ('virginica', 2)]:\n",
    "    ax.text3D(\n",
    "        x[Y == label, 0].mean(),\n",
    "        x[Y == label, 1].mean() + 2,\n",
    "        x[Y == label, 2].mean(),\n",
    "        name,\n",
    "        horizontalalignment='center',\n",
    "        bbox=dict(alpha=0.5, edgecolor='w', facecolor='w')\n",
    "    )\n",
    "\n",
    "y = np.choose(Y, [1, 2, 0]).astype(float)\n",
    "ax.scatter(x[:,0], x[:,1], x[:,2], c=y, cmap = plt.cm.nipy_spectral, edgecolor='k')\n",
    "\n",
    "ax.xaxis.set_ticklabels([])\n",
    "ax.yaxis.set_ticklabels([])\n",
    "ax.zaxis.set_ticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034c6eb-d12d-4c16-8365-11e9c8e274d4",
   "metadata": {},
   "source": [
    "# 3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e2c8f-52e2-492c-9c97-8aaf04e1f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "Y = 4 + 3 * np.random.rand(100, 1) \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lin_reg.predict(X_test) \n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "cv = rmse / np.var(Y)\n",
    "print(f'Mean Squared Error: {mse} \\nRoot Mean Squared Error: {rmse} \\nMean Absolute Error: {mae} \\nCo-Efficient of variation: {cv}')\n",
    "\n",
    "plt.scatter(X_train, Y_train, color='b', label='Training Data')\n",
    "plt.scatter(X_test, Y_test, color='g', label='Test Data')\n",
    "plt.plot(X_test, Y_pred, color='r', linewidth = 2, label = 'Fitted line')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df6fec-bb18-45bf-9c2f-efacce5ed8d6",
   "metadata": {},
   "source": [
    "# 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290e7d0-3857-4537-80bc-e13770f1d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(Y_test, Y_pred)}')\n",
    "print(f'Classification Report: \\n{classification_report(Y_test, Y_pred)}')\n",
    "print(f'Accuracy: {accuracy_score(Y_test, Y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26433e55-1749-4a7b-9395-f6661177168f",
   "metadata": {},
   "source": [
    "# 5. Linear Discriminant Algorithm(LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85869a02-a9d2-403a-9741-b44ccf50d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lda.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "class_report = classification_report(Y_test, Y_pred)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Confusion matrix: \\n', conf_matrix)\n",
    "print('Classification Report: \\n',class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff8379-df41-4c48-a3ac-945a1c01116d",
   "metadata": {},
   "source": [
    "# 6. Singular Value Decomposition(SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074fe5f-f75c-483b-8b21-51db80745fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "U, S, VT = np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "print('Matrix A:\\n',A)\n",
    "print('\\nU Matrix:\\n', U)\n",
    "print('\\nSingular Values:\\n', S)\n",
    "print('\\nVT Matrix:\\n', VT)\n",
    "\n",
    "sigma = np.diag(S)\n",
    "\n",
    "A_reconstructed = np.dot(U, np.dot(sigma, VT))\n",
    "print('\\nReconstructed Matrix A:\\n', A_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52be761-c866-492a-b662-7f0f29e020be",
   "metadata": {},
   "source": [
    "# 7. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ecbf5-7b3c-4815-ac2b-caf682a2605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "datasets = load_iris()\n",
    "\n",
    "X = datasets.data\n",
    "Y = datasets.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "GNB = GaussianNB()\n",
    "classifier = GNB.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "\n",
    "print('Accuracy Matrices: \\n', classification_report(Y_test, Y_pred))\n",
    "print('Accuracy of the matrices is: ',metrics.accuracy_score(Y_test, Y_pred))\n",
    "print('\\nConfusion matrics: \\n',metrics.confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588aa020-22b0-46c6-b407-6c590cc81bd5",
   "metadata": {},
   "source": [
    "# 8. AND operation using perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e9d1f-2ca8-4fea-b1f0-b9184740d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(out, threshold):\n",
    "    if out >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def perceptron(and_input):\n",
    "    A = [0, 0, 1, 1]\n",
    "    B = [0, 1, 0, 1]\n",
    "    Y = [0, 0, 0, 1]\n",
    "    W = [1.4, 1.5]\n",
    "    threshold = 1\n",
    "    learning_rate = 0.1\n",
    "    i = 0\n",
    "    print('Perceptron Training: \\n')\n",
    "    while i < 4:\n",
    "        summation = A[i] * W[0] + B[i] * W[1]\n",
    "        o = activation(summation, threshold)\n",
    "        print('Input: '+str(A[i]) + ',' + str(B[i]))\n",
    "        print('Weight: '+str(W[0])+','+str(W[1]))\n",
    "        print('Summation: '+str(summation)+' Threshold: '+str(threshold))\n",
    "        print('Actual Output: '+str(Y[i]) + ' Predicted Output: '+str(o))\n",
    "        if (o != Y[i]):\n",
    "            print('\\nUpdated Weights')\n",
    "            W[0] = W[0] + learning_rate * (Y[i] - o) * A[i]\n",
    "            W[1] = W[1] + learning_rate * (Y[i] - o) * B[i]\n",
    "            print('Updated weights: '+str(W[0]) + ',' +str(W[1]))\n",
    "            i = -1 \n",
    "            print(\"\\nWeight Updated Training Again\")\n",
    "        i += 1\n",
    "        print('-----------')\n",
    "    summation = and_input[0] * W[0] + and_input[1] * W[1]\n",
    "    return activation(summation, threshold)\n",
    "\n",
    "and_input = [1, 1]\n",
    "print('AND gate output for '+str(and_input)+': '+str(perceptron(and_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ad755-d318-4f37-b907-921d0f3b83b9",
   "metadata": {},
   "source": [
    "# 9. OR operation using percetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e68bdf-c497-4f0e-8851-ae1ece2f03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(out, threshold):\n",
    "    if out > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def perceptron(or_input):\n",
    "    A = [0, 0, 1, 1]\n",
    "    B = [0, 1, 0, 1] \n",
    "    Y = [0, 1, 1, 1]  \n",
    "    W = [0.0, 0.3]  \n",
    "    threshold = 0.4 \n",
    "    learning_rate = 0.5  \n",
    "    i = 0\n",
    "    print('Perceptron Training: \\n')\n",
    "    \n",
    "    while i < 4:\n",
    "        summation = A[i] * W[0] + B[i] * W[1]\n",
    "        o = activation(summation, threshold)  \n",
    "        print(f'Input: {A[i]}, {B[i]}')\n",
    "        print(f'Weight: {W[0]:.2f}, {W[1]:.2f}')\n",
    "        print(f'Summation: {summation:.2f} Threshold: {threshold}')\n",
    "        print(f'Actual Output: {Y[i]} Predicted Output: {o}')\n",
    "        \n",
    "        if o != Y[i]:  \n",
    "            print('\\nUpdated Weights')\n",
    "            W[0] += learning_rate * (Y[i] - o) * A[i]\n",
    "            W[1] += learning_rate * (Y[i] - o) * B[i]\n",
    "            print(f'Updated weights: {W[0]:.2f}, {W[1]:.2f}')\n",
    "            i = -1  \n",
    "            print(\"\\nWeight Updated, Training Again\")\n",
    "        \n",
    "        i += 1\n",
    "        print('-----------')\n",
    "    \n",
    "    summation = or_input[0] * W[0] + or_input[1] * W[1]\n",
    "    return activation(summation, threshold)\n",
    "\n",
    "or_input = [0, 0] \n",
    "print(f'OR gate output for {or_input}: {perceptron(or_input)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb8a23-d99a-4722-b4e0-0127b80bab9a",
   "metadata": {},
   "source": [
    "# 10. Back-propogation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b562e-9fe3-400f-b10c-dece3f19a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[2, 9], [1, 5], [3, 6]], dtype=float)\n",
    "Y = np.array([[92], [86], [89]], dtype=float)\n",
    "\n",
    "X = X / np.amax(X, axis=0)\n",
    "Y = Y / 100\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "epoch = 7000\n",
    "lr = 0.1\n",
    "inputlayer_neurons = 2\n",
    "hiddenlayer_neurons = 3\n",
    "output_neurons = 1\n",
    "\n",
    "wh   = np.random.uniform(size=(inputlayer_neurons, hiddenlayer_neurons))\n",
    "bh   = np.random.uniform(size=(1, hiddenlayer_neurons))\n",
    "wout = np.random.uniform(size=(hiddenlayer_neurons, output_neurons))\n",
    "bout = np.random.uniform(size=(1, output_neurons))\n",
    "\n",
    "for i in range(epoch):\n",
    "    hinpl      = np.dot(X, wh)\n",
    "    hinp       = hinpl + bh\n",
    "    hlayer_act = sigmoid(hinp)\n",
    "\n",
    "    outinpl = np.dot(hlayer_act, wout)\n",
    "    outinp  = outinpl + bout\n",
    "    output  = sigmoid(outinp)\n",
    "\n",
    "    E0 = Y - output\n",
    "    outgrad  = derivatives_sigmoid(output)\n",
    "    d_output = E0 * outgrad\n",
    "\n",
    "    EH = d_output.dot(wout.T)\n",
    "    hiddengrad = derivatives_sigmoid(hlayer_act)\n",
    "    d_hiddenlayer = EH * hiddengrad\n",
    "\n",
    "    wout += hlayer_act.T.dot(d_output) * lr\n",
    "    wh += X.T.dot(d_hiddenlayer) * lr\n",
    "\n",
    "print('Input: \\n'+str(X))\n",
    "print('Actual output: \\n'+str(Y))\n",
    "print('Predicted Output: \\n',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c977028-3f44-478e-bb79-641194fa01ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
